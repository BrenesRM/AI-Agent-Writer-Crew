velCoordinator({
            'max_iterations': 3,
            'quality_threshold': 0.75
        })
        
        # Verificar inicializaci√≥n
        status = coordinator.get_status()
        assert not status['is_running']
        assert status['components']['workflow_graph']['is_valid']
        print(f"   ‚úÖ Coordinator inicializado correctamente")
        
        # Test procesamiento completo (simulado)
        test_manuscript = """
        En el reino de Eldoria, donde la magia fluye como r√≠os de luz dorada, 
        un joven h√©roe llamado Aiden debe enfrentar al malvado hechicero Malachar.
        
        Los dragones antiguos han despertado, y solo el elegido puede reunir 
        las tres piedras del poder para restaurar el equilibrio.
        
        Con su fiel compa√±era Lyra y el sabio mago Eldrin, Aiden emprende 
        una √©pica aventura que pondr√° a prueba su valor y determinaci√≥n.
        
        Las fuerzas del mal se congregan en la Torre Negra, mientras que 
        nuestros h√©roes deben superar pruebas mortales y descubrir secretos 
        ancestrales que cambiar√°n el destino del reino para siempre.
        """
        
        test_requirements = {
            'genre': 'epic_fantasy',
            'target_audience': 'young_adult',
            'target_length': 80000,
            'themes': ['heroism', 'friendship', 'good_vs_evil']
        }
        
        # Ejecutar procesamiento (esto deber√≠a completarse con simulaciones)
        results = await coordinator.process_manuscript(
            manuscript=test_manuscript,
            requirements=test_requirements
        )
        
        # Verificar resultados
        assert 'session_id' in results
        assert 'processing_summary' in results
        assert 'analysis_results' in results
        assert results['processing_summary']['status'] in ['completed', 'partial_completion']
        
        print(f"   ‚úÖ Procesamiento completado:")
        print(f"      - Sesi√≥n: {results['session_id']}")
        print(f"      - Iteraciones: {results['processing_summary']['iterations']}")
        print(f"      - Nodos completados: {results['processing_summary']['completed_nodes']}")
        print(f"      - Estado: {results['processing_summary']['status']}")
        
        # Verificar an√°lisis generados
        if results['analysis_results']:
            print(f"      - An√°lisis disponibles: {list(results['analysis_results'].keys())}")
        
        # Verificar recomendaciones
        if results['recommendations']:
            print(f"      - Recomendaciones: {len(results['recommendations'])}")
        
        print(f"   ‚úÖ Integraci√≥n completa funcionando")
        
    except Exception as e:
        print(f"   ‚ùå Error en Coordinator: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # Test 6: Node Execution
    print("\nüîß Probando Ejecuci√≥n de Nodos...")
    try:
        # Test nodo individual
        from orchestrator.workflow_graph import LorekeeperNode
        
        lorekeeper = LorekeeperNode()
        test_state = {
            'manuscript': test_manuscript,
            'completed_nodes': []
        }
        
        result = await lorekeeper.execute(test_state, {})
        
        assert result.status == 'completed'
        assert 'worldbuilding_analysis' in result.data
        assert result.processing_time > 0
        
        analysis = result.data['worldbuilding_analysis']
        assert 'lore_elements' in analysis
        assert 'consistency_score' in analysis
        assert isinstance(analysis['consistency_score'], int)
        
        print(f"   ‚úÖ Nodo Lorekeeper ejecutado correctamente")
        print(f"      - Elementos: {analysis['lore_elements']}")
        print(f"      - Puntuaci√≥n: {analysis['consistency_score']}")
        print(f"      - Tiempo: {result.processing_time:.2f}s")
        
        # Test nodo con dependencias
        from orchestrator.workflow_graph import PlotWeaverNode
        
        plot_weaver = PlotWeaverNode()
        state_with_deps = {
            'manuscript': test_manuscript,
            'completed_nodes': ['lorekeeper_analysis', 'character_development'],
            'analysis_results': {
                'worldbuilding': analysis,
                'character_development': {'character_development_score': 80}
            }
        }
        
        plot_result = await plot_weaver.execute(state_with_deps, {})
        
        assert plot_result.status == 'completed'
        assert 'plot_analysis' in plot_result.data
        
        plot_analysis = plot_result.data['plot_analysis']
        assert 'structure_score' in plot_analysis
        
        print(f"   ‚úÖ Nodo Plot Weaver ejecutado correctamente")
        print(f"      - Estructura: {plot_analysis['structure_score']}")
        print(f"      - Ritmo: {plot_analysis['pacing_rating']}")
        
    except Exception as e:
        print(f"   ‚ùå Error ejecutando nodos: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # Test 7: Error Handling
    print("\n‚ö†Ô∏è  Probando Manejo de Errores...")
    try:
        # Test con manuscrito vac√≠o
        try:
            await coordinator.process_manuscript("", {})
            print(f"   ‚ùå Deber√≠a fallar con manuscrito vac√≠o")
            return False
        except ValueError:
            print(f"   ‚úÖ Error capturado correctamente para manuscrito vac√≠o")
        
        # Test nodo con datos faltantes
        broken_state = {'manuscript': ''}
        result = await lorekeeper.execute(broken_state, {})
        assert result.status == 'failed'
        assert result.error is not None
        print(f"   ‚úÖ Error de nodo manejado correctamente")
        
        # Test l√≠mite de tiempo
        from orchestrator.workflow_graph import BaseWorkflowNode, NodeType
        
        class SlowNode(BaseWorkflowNode):
            def __init__(self):
                super().__init__("test_slow", "Slow Node", NodeType.ANALYSIS, [], timeout=1)
            
            async def _execute_logic(self, state, params):
                await asyncio.sleep(2)  # M√°s tiempo que el timeout
                return {'data': 'should_not_reach'}
        
        slow_node = SlowNode()
        timeout_result = await slow_node.execute({'manuscript': 'test'}, {})
        assert timeout_result.status == 'timeout'
        print(f"   ‚úÖ Timeout manejado correctamente")
        
    except Exception as e:
        print(f"   ‚ùå Error probando manejo de errores: {e}")
        return False
    
    # Test 8: Performance and Scalability
    print("\n‚ö° Probando Rendimiento...")
    try:
        import time
        
        # Test m√∫ltiples ejecuciones
        start_time = time.time()
        
        tasks = []
        for i in range(3):
            task = lorekeeper.execute({
                'manuscript': f"Test manuscript {i} with magic and dragons",
                'completed_nodes': []
            }, {})
            tasks.append(task)
        
        results = await asyncio.gather(*tasks)
        end_time = time.time()
        
        successful = sum(1 for r in results if r.status == 'completed')
        total_time = end_time - start_time
        
        print(f"   ‚úÖ Ejecuciones paralelas completadas:")
        print(f"      - Total: {len(results)}")
        print(f"      - Exitosas: {successful}")
        print(f"      - Tiempo total: {total_time:.2f}s")
        print(f"      - Promedio por ejecuci√≥n: {total_time/len(results):.2f}s")
        
        # Verificar que el paralelismo funcion√≥ (deber√≠a ser m√°s r√°pido que secuencial)
        assert total_time < sum(r.processing_time for r in results), "Paralelismo no est√° funcionando"
        print(f"   ‚úÖ Paralelismo funcionando correctamente")
        
    except Exception as e:
        print(f"   ‚ùå Error probando rendimiento: {e}")
        return False
    
    # Resumen final
    print("\n" + "=" * 70)
    print("üìã RESUMEN DE PRUEBAS")
    print("=" * 70)
    
    test_results = {
        'Workflow Graph': '‚úÖ PASS',
        'State Manager': '‚úÖ PASS',
        'Decision Engine': '‚úÖ PASS',
        'Iteration Controller': '‚úÖ PASS',
        'Coordinator Integration': '‚úÖ PASS',
        'Node Execution': '‚úÖ PASS',
        'Error Handling': '‚úÖ PASS',
        'Performance': '‚úÖ PASS'
    }
    
    for test_name, result in test_results.items():
        print(f"{test_name:<25} {result}")
    
    print("\nüéâ TODAS LAS PRUEBAS COMPLETADAS EXITOSAMENTE")
    print("üöÄ El sistema orchestrator est√° listo para uso en producci√≥n")
    
    return True

async def test_individual_components():
    """Pruebas individuales detalladas"""
    
    print("\nüî¨ PRUEBAS DETALLADAS DE COMPONENTES")
    print("=" * 50)
    
    # Test Decision Engine en detalle
    print("\nü§ñ An√°lisis Detallado del Decision Engine...")
    
    from orchestrator.decision_engine import DecisionEngine, ActionPriority
    
    engine = DecisionEngine()
    
    # Escenario 1: Inicio limpio
    clean_state = {
        'iteration': 0,
        'completed_nodes': [],
        'failed_nodes': [],
        'analysis_results': {},
        'error_log': []
    }
    
    actions = await engine.get_next_actions(clean_state)
    print(f"   Inicio limpio: {len(actions)} acciones")
    for action in actions:
        print(f"     - {action['id']} (prioridad: {action['priority']})")
    
    # Escenario 2: Algunas completadas
    partial_state = {
        'iteration': 1,
        'completed_nodes': ['lorekeeper_analysis', 'character_development'],
        'failed_nodes': [],
        'analysis_results': {
            'worldbuilding': {'consistency_score': 85},
            'character_development': {'character_development_score': 78}
        },
        'error_log': []
    }
    
    actions = await engine.get_next_actions(partial_state)
    print(f"   Estado parcial: {len(actions)} acciones")
    for action in actions:
        print(f"     - {action['id']} (prioridad: {action['priority']})")
    
    # Escenario 3: Con errores
    error_state = {
        'iteration': 2,
        'completed_nodes': ['lorekeeper_analysis'],
        'failed_nodes': ['character_development'],
        'analysis_results': {'worldbuilding': {'consistency_score': 85}},
        'error_log': [
            {'node_id': 'character_development', 'iteration': 1},
            {'node_id': 'character_development', 'iteration': 2}
        ]
    }
    
    actions = await engine.get_next_actions(error_state)
    print(f"   Estado con errores: {len(actions)} acciones")
    for action in actions:
        retry_info = " (RETRY)" if action['params'].get('is_retry') else ""
        print(f"     - {action['id']}{retry_info} (prioridad: {action['priority']})")
    
    # Test Workflow Graph en detalle
    print("\nüìä An√°lisis Detallado del Workflow Graph...")
    
    from orchestrator.workflow_graph import WorkflowGraph
    
    graph = WorkflowGraph()
    
    # An√°lisis de dependencias
    print("   Dependencias por nodo:")
    for node_id, node in graph.nodes.items():
        deps = ", ".join(node.dependencies) if node.dependencies else "Ninguna"
        print(f"     - {node_id}: {deps}")
    
    # An√°lisis de paralelismo
    all_nodes = list(graph.nodes.keys())
    parallel_groups = graph.get_parallel_groups(all_nodes)
    print(f"   Grupos de paralelismo: {len(parallel_groups)}")
    for i, group in enumerate(parallel_groups):
        print(f"     - Grupo {i+1}: {group}")
    
    # Camino cr√≠tico
    critical_path = graph.get_critical_path()
    print(f"   Camino cr√≠tico: {' -> '.join(critical_path)}")
    
    # Estad√≠sticas de nodos
    node_details = graph.get_node_details()
    print("   Detalles de nodos:")
    for node_id, details in node_details.items():
        parallel = "S√≠" if details['parallel_safe'] else "No"
        required = "S√≠" if details['required'] else "No"
        print(f"     - {details['name']}:")
        print(f"       * Tipo: {details['type']}")
        print(f"       * Paralelo: {parallel}")
        print(f"       * Requerido: {required}")
        print(f"       * Timeout: {details['timeout']}s")

def main():
    """Funci√≥n principal"""
    print("üîß Iniciando pruebas del sistema Orchestrator...")
    
    try:
        # Ejecutar pruebas principales
        success = asyncio.run(test_orchestrator())
        
        if success:
            # Ejecutar pruebas detalladas
            asyncio.run(test_individual_components())
            
            print("\n" + "=" * 70)
            print("üèÜ TODAS LAS PRUEBAS COMPLETADAS EXITOSAMENTE")
            print("üìà Sistema Orchestrator validado y listo para producci√≥n")
            print("=" * 70)
            return 0
        else:
            print("\n‚ùå ALGUNAS PRUEBAS FALLARON")
            return 1
            
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Pruebas interrumpidas por el usuario")
        return 1
    except Exception as e:
        print(f"\nüí• Error cr√≠tico en pruebas: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    exit_code = main()
    input("\nPresiona Enter para continuar...")
    sys.exit(exit_code)
