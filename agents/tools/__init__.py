# agents/tools/__init__.py
from .rag_tool import RAGTool
from .writing_tools import WritingAnalyzer, StyleAnalyzer, CharacterAnalyzer
from .analysis_tools import ConsistencyChecker, PacingAnalyzer, PlotAnalyzer
from .creative_tools import IdeaGenerator, VisualPromptGenerator

__all__ = [
    'RAGTool',
    'WritingAnalyzer', 
    'StyleAnalyzer',
    'CharacterAnalyzer',
    'ConsistencyChecker',
    'PacingAnalyzer', 
    'PlotAnalyzer',
    'IdeaGenerator',
    'VisualPromptGenerator'
]


# agents/tools/rag_tool.py
import logging
from typing import Dict, Any, Optional, List
from crewai_tools import BaseTool
from pydantic import BaseModel, Field
import sys
from pathlib import Path

# A√±adir el directorio ra√≠z al path
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from rag.rag_manager import RAGManager

class RAGToolInput(BaseModel):
    query: str = Field(..., description="La consulta a realizar en la base de conocimiento")
    doc_type: Optional[str] = Field(None, description="Tipo de documento espec√≠fico a buscar")
    k: int = Field(5, description="N√∫mero m√°ximo de documentos relevantes a retornar")

class RAGTool(BaseTool):
    name: str = "Consultar Base de Conocimiento"
    description: str = """
    Herramienta para consultar la base de conocimiento RAG con documentos de referencia.
    √ötil para obtener informaci√≥n sobre lore, personajes, reglas del mundo, referencias hist√≥ricas,
    y cualquier otro contexto relevante para la historia.
    """
    args_schema: type[BaseModel] = RAGToolInput
    
    def __init__(self, **data):
        super().__init__(**data)
        self.rag_manager = RAGManager()
        self.logger = logging.getLogger(__name__)
    
    def _run(self, query: str, doc_type: Optional[str] = None, k: int = 5) -> str:
        """Ejecuta una consulta en el sistema RAG"""
        try:
            self.logger.info(f"Consultando RAG: {query}")
            
            result = self.rag_manager.query(query, k=k, doc_type=doc_type)
            
            if not result['context']:
                return f"No se encontr√≥ informaci√≥n relevante para: {query}"
            
            # Formatear respuesta
            response = f"INFORMACI√ìN ENCONTRADA para '{query}':\n\n"
            response += result['context']
            response += f"\n\nFuentes consultadas: {result['num_sources']} documentos"
            
            return response
            
        except Exception as e:
            self.logger.error(f"Error en consulta RAG: {str(e)}")
            return f"Error consultando la base de conocimiento: {str(e)}"


# agents/tools/writing_tools.py
import re
import logging
from typing import Dict, Any, List, Tuple
from crewai_tools import BaseTool
from pydantic import BaseModel, Field
import nltk
from collections import Counter
from textblob import TextBlob

# Descargar recursos necesarios de NLTK (solo primera vez)
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')

try:
    nltk.data.find('taggers/averaged_perceptron_tagger')
except LookupError:
    nltk.download('averaged_perceptron_tagger')

class WritingAnalyzerInput(BaseModel):
    text: str = Field(..., description="Texto a analizar")

class WritingAnalyzer(BaseTool):
    name: str = "Analizador de Escritura"
    description: str = """
    Analiza un texto narrativo y proporciona estad√≠sticas detalladas:
    - Conteo de palabras, p√°rrafos, oraciones
    - Longitud promedio de oraciones
    - Diversidad l√©xica
    - An√°lisis de legibilidad
    """
    args_schema: type[BaseModel] = WritingAnalyzerInput
    
    def _run(self, text: str) -> str:
        """Analiza las caracter√≠sticas generales de un texto"""
        try:
            # Estad√≠sticas b√°sicas
            words = len(text.split())
            sentences = len(nltk.sent_tokenize(text))
            paragraphs = len([p for p in text.split('\n\n') if p.strip()])
            characters = len(text)
            
            # Longitud promedio de oraciones
            avg_sentence_length = words / max(sentences, 1)
            
            # Diversidad l√©xica
            unique_words = len(set(word.lower() for word in text.split()))
            lexical_diversity = unique_words / max(words, 1)
            
            # Palabras m√°s frecuentes
            word_counts = Counter(word.lower().strip('.,!?;:"()[]') for word in text.split())
            most_common = word_counts.most_common(5)
            
            analysis = f"""AN√ÅLISIS DE ESCRITURA:
            
üìä ESTAD√çSTICAS B√ÅSICAS:
- Palabras: {words:,}
- Oraciones: {sentences:,}
- P√°rrafos: {paragraphs:,}
- Caracteres: {characters:,}

üìè M√âTRICAS DE ESTILO:
- Longitud promedio de oraci√≥n: {avg_sentence_length:.1f} palabras
- Diversidad l√©xica: {lexical_diversity:.2%}

üî§ PALABRAS M√ÅS FRECUENTES:
{chr(10).join([f"- {word}: {count} veces" for word, count in most_common])}

üìñ EVALUACI√ìN:
- Complejidad: {'Alta' if avg_sentence_length > 20 else 'Media' if avg_sentence_length > 15 else 'Baja'}
- Variedad vocabulario: {'Rica' if lexical_diversity > 0.7 else 'Media' if lexical_diversity > 0.5 else 'Limitada'}
"""
            return analysis
            
        except Exception as e:
            return f"Error analizando texto: {str(e)}"

class StyleAnalyzerInput(BaseModel):
    text: str = Field(..., description="Texto a analizar estil√≠sticamente")

class StyleAnalyzer(BaseTool):
    name: str = "Analizador de Estilo"
    description: str = """
    Analiza el estilo narrativo de un texto:
    - Tono y sentimiento
    - Uso de di√°logos
    - Perspectiva narrativa
    - Tiempo verbal dominante
    """
    args_schema: type[BaseModel] = StyleAnalyzerInput
    
    def _run(self, text: str) -> str:
        """Analiza el estilo narrativo del texto"""
        try:
            blob = TextBlob(text)
            
            # An√°lisis de sentimientos
            sentiment = blob.sentiment
            
            # Detectar di√°logos
            dialogue_count = len(re.findall(r'["\'].*?["\']', text))
            dialogue_percentage = (dialogue_count * 100) / max(len(text.split()), 1)
            
            # Detectar perspectiva narrativa
            first_person = len(re.findall(r'\b(yo|me|mi|nosotros|nos)\b', text.lower()))
            third_person = len(re.findall(r'\b(√©l|ella|ellos|ellas)\b', text.lower()))
            
            if first_person > third_person:
                perspective = "Primera persona"
            elif third_person > first_person:
                perspective = "Tercera persona"
            else:
                perspective = "Mixta o indefinida"
            
            # An√°lisis de tiempo verbal (simple)
            past_tense = len(re.findall(r'\w+(√≥|√≠a|aba|ieron|ado|ido)\b', text))
            present_tense = len(re.findall(r'\w+(a|e|o|an|en|on)\b', text))
            
            dominant_tense = "Pasado" if past_tense > present_tense else "Presente"
            
            # Determinar tono
            if sentiment.polarity > 0.1:
                tone = "Positivo"
            elif sentiment.polarity < -0.1:
                tone = "Negativo"
            else:
                tone = "Neutral"
            
            analysis = f"""AN√ÅLISIS DE ESTILO:
            
üé≠ TONO Y SENTIMIENTO:
- Polaridad: {sentiment.polarity:.2f} (-1 negativo, +1 positivo)
- Subjetividad: {sentiment.subjectivity:.2f} (0 objetivo, 1 subjetivo)  
- Tono general: {tone}

üë• PERSPECTIVA NARRATIVA:
- Perspectiva dominante: {perspective}
- Marcadores 1¬™ persona: {first_person}
- Marcadores 3¬™ persona: {third_person}

üïê TIEMPO NARRATIVO:
- Tiempo dominante: {dominant_tense}
- Marcadores de pasado: {past_tense}
- Marcadores de presente: {present_tense}

üí¨ DI√ÅLOGOS:
- Fragmentos de di√°logo detectados: {dialogue_count}
- Porcentaje estimado de di√°logo: {dialogue_percentage:.1f}%

üìù RECOMENDACIONES:
- {'Considera variar la perspectiva para mayor dinamismo' if perspective == 'Mixta o indefinida' else '‚úì Perspectiva narrativa consistente'}
- {'Equilibra narraci√≥n y di√°logo' if dialogue_percentage < 10 or dialogue_percentage > 50 else '‚úì Buen balance narraci√≥n/di√°logo'}
"""
            return analysis
            
        except Exception as e:
            return f"Error analizando estilo: {str(e)}"

class CharacterAnalyzerInput(BaseModel):
    text: str = Field(..., description="Texto que contiene personajes a analizar")

class CharacterAnalyzer(BaseTool):
    name: str = "Analizador de Personajes"
    description: str = """
    Identifica y analiza personajes en un texto narrativo:
    - Extrae nombres de personajes
    - Cuenta menciones de cada personaje
    - Identifica roles y relaciones
    """
    args_schema: type[BaseModel] = CharacterAnalyzerInput
    
    def _run(self, text: str) -> str:
        """Analiza los personajes presentes en el texto"""
        try:
            # Extraer nombres propios (patr√≥n simple)
            names = re.findall(r'\b[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+(?:\s+[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+)*\b', text)
            
            # Filtrar nombres comunes que no son personajes
            common_words = {'El', 'La', 'Los', 'Las', 'Un', 'Una', 'Por', 'Para', 'Con', 'Sin', 'Sobre', 'Desde', 'Hasta'}
            character_names = [name for name in names if name not in common_words and len(name) > 2]
            
            # Contar menciones
            character_counts = Counter(character_names)
            
            # Buscar relaciones (patrones simples)
            relationships = []
            for char in character_counts.keys():
                # Buscar patrones de relaci√≥n
                if re.search(rf'{char}.*?(hermano|hermana|padre|madre|hijo|hija)', text, re.IGNORECASE):
                    relationships.append(f"{char} - relaci√≥n familiar mencionada")
                if re.search(rf'{char}.*?(amigo|amiga|enemigo|enemiga)', text, re.IGNORECASE):
                    relationships.append(f"{char} - relaci√≥n de amistad/enemistad mencionada")
                if re.search(rf'{char}.*?(rey|reina|pr√≠ncipe|princesa|lord|lady)', text, re.IGNORECASE):
                    relationships.append(f"{char} - posible rol de nobleza")
            
            analysis = f"""AN√ÅLISIS DE PERSONAJES:
            
üë• PERSONAJES IDENTIFICADOS:
{chr(10).join([f"- {char}: {count} menciones" for char, count in character_counts.most_common(10)])}

üîó RELACIONES DETECTADAS:
{chr(10).join([f"- {rel}" for rel in relationships]) if relationships else "- No se detectaron relaciones expl√≠citas"}

üìä ESTAD√çSTICAS:
- Total de personajes √∫nicos: {len(character_counts)}
- Personaje m√°s mencionado: {character_counts.most_common(1)[0][0] if character_counts else 'Ninguno'} 
- Distribuci√≥n de menciones: {'Equilibrada' if len(set(character_counts.values())) > 3 else 'Concentrada'}

üí° OBSERVACIONES:
- {'Historia centrada en pocos personajes' if len(character_counts) < 5 else 'Historia con amplio elenco de personajes'}
- {'Considerar desarrollar m√°s a los personajes secundarios' if len(character_counts) > 1 and character_counts.most_common(1)[0][1] > sum(character_counts.values()) * 0.5 else '‚úì Buen equilibrio entre personajes'}
"""
            return analysis
            
        except Exception as e:
            return f"Error analizando personajes: {str(e)}"


# agents/tools/analysis_tools.py
import re
import logging
from typing import Dict, Any, List
from crewai_tools import BaseTool
from pydantic import BaseModel, Field

class ConsistencyCheckerInput(BaseModel):
    text: str = Field(..., description="Texto a verificar por consistencia")
    reference_text: str = Field("", description="Texto de referencia para comparar consistencia")

class ConsistencyChecker(BaseTool):
    name: str = "Verificador de Consistencia"
    description: str = """
    Verifica la consistencia interna de un texto narrativo:
    - Detecta contradicciones en nombres y descripciones
    - Verifica continuidad temporal
    - Identifica inconsistencias en caracter√≠sticas de personajes
    """
    args_schema: type[BaseModel] = ConsistencyCheckerInput
    
    def _run(self, text: str, reference_text: str = "") -> str:
        """Verifica la consistencia del texto"""
        try:
            issues = []
            
            # Extraer nombres de personajes y lugares
            names = re.findall(r'\b[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+(?:\s+[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+)*\b', text)
            
            # Buscar variaciones en nombres (posibles inconsistencias)
            name_variations = {}
            for name in set(names):
                similar_names = [n for n in set(names) if n != name and (
                    name.startswith(n) or n.startswith(name) or 
                    abs(len(name) - len(n)) <= 2
                )]
                if similar_names:
                    name_variations[name] = similar_names
            
            if name_variations:
                issues.append("POSIBLES VARIACIONES EN NOMBRES:")
                for main_name, variations in name_variations.items():
                    issues.append(f"- {main_name} vs {', '.join(variations)}")
            
            # Verificar marcadores temporales
            time_markers = re.findall(r'\b(ayer|hoy|ma√±ana|hace\s+\w+|despu√©s\s+de\s+\w+|antes\s+de\s+\w+)\b', text.lower())
            if len(set(time_markers)) > 5:
                issues.append("ADVERTENCIA: M√∫ltiples marcadores temporales - verificar cronolog√≠a")
            
            # Buscar contradictions en descripci√≥n f√≠sica
            physical_descriptions = re.findall(r'(ojos\s+\w+|cabello\s+\w+|pelo\s+\w+|altura\s+\w+)', text.lower())
            if len(physical_descriptions) > len(set(physical_descriptions)):
                issues.append("POSIBLE INCONSISTENCIA: Descripciones f√≠sicas repetidas o contradictorias")
            
            # Comparar con texto de referencia si se proporciona
            if reference_text:
                ref_names = set(re.findall(r'\b[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+(?:\s+[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+)*\b', reference_text))
                text_names = set(names)
                
                new_names = text_names - ref_names
                missing_names = ref_names - text_names
                
                if new_names:
                    issues.append(f"PERSONAJES NUEVOS: {', '.join(new_names)}")
                if missing_names:
                    issues.append(f"PERSONAJES AUSENTES: {', '.join(missing_names)}")
            
            if not issues:
                return "‚úÖ No se detectaron inconsistencias evidentes en el texto."
            else:
                return "üîç VERIFICACI√ìN DE CONSISTENCIA:\n\n" + "\n".join(issues)
                
        except Exception as e:
            return f"Error verificando consistencia: {str(e)}"

class PacingAnalyzerInput(BaseModel):
    text: str = Field(..., description="Texto para analizar el ritmo narrativo")

class PacingAnalyzer(BaseTool):
    name: str = "Analizador de Ritmo"
    description: str = """
    Analiza el ritmo y flujo narrativo del texto:
    - Identifica variaci√≥n en longitud de p√°rrafos y oraciones
    - Detecta momentos de acci√≥n vs. reflexi√≥n
    - Eval√∫a el balance narrativo
    """
    args_schema: type[BaseModel] = PacingAnalyzerInput
    
    def _run(self, text: str) -> str:
        """Analiza el ritmo narrativo del texto"""
        try:
            # Dividir en p√°rrafos
            paragraphs = [p.strip() for p in text.split('\n\n') if p.strip()]
            
            if not paragraphs:
                return "‚ùå No se pudieron identificar p√°rrafos en el texto."
            
            # An√°lisis de longitud de p√°rrafos
            paragraph_lengths = [len(p.split()) for p in paragraphs]
            avg_paragraph_length = sum(paragraph_lengths) / len(paragraph_lengths)
            
            # Variaci√≥n en longitud de p√°rrafos
            length_variation = max(paragraph_lengths) - min(paragraph_lengths)
            
            # Detectar p√°rrafos de acci√≥n (oraciones cortas, verbos din√°micos)
            action_keywords = ['corri√≥', 'salt√≥', 'grit√≥', 'atac√≥', 'luch√≥', 'escap√≥', 'golpe√≥', 'dispar√≥']
            action_paragraphs = []
            
            for i, p in enumerate(paragraphs):
                sentences = p.split('.')
                avg_sentence_length = sum(len(s.split()) for s in sentences) / max(len(sentences), 1)
                action_words = sum(1 for word in action_keywords if word.lower() in p.lower())
                
                if avg_sentence_length < 12 or action_words > 0:
                    action_paragraphs.append(i + 1)
            
            # Detectar p√°rrafos reflexivos (oraciones largas, palabras introspectivas)
            reflection_keywords = ['pens√≥', 'reflexion√≥', 'record√≥', 'sinti√≥', 'consider√≥', 'medit√≥']
            reflective_paragraphs = []
            
            for i, p in enumerate(paragraphs):
                sentences = p.split('.')
                avg_sentence_length = sum(len(s.split()) for s in sentences) / max(len(sentences), 1)
                reflection_words = sum(1 for word in reflection_keywords if word.lower() in p.lower())
                
                if avg_sentence_length > 20 or reflection_words > 0:
                    reflective_paragraphs.append(i + 1)
            
            # Evaluar el ritmo general
            if length_variation < 20:
                rhythm_assessment = "Ritmo uniforme - considera variar la longitud de p√°rrafos"
            elif length_variation > 100:
                rhythm_assessment = "Ritmo muy variable - buen dinamismo narrativo"
            else:
                rhythm_assessment = "Ritmo balanceado"
            
            analysis = f"""AN√ÅLISIS DE RITMO NARRATIVO:
            
üìè ESTRUCTURA:
- Total de p√°rrafos: {len(paragraphs)}
- Longitud promedio: {avg_paragraph_length:.1f} palabras por p√°rrafo
- Variaci√≥n de longitud: {length_variation} palabras
- P√°rrafo m√°s corto: {min(paragraph_lengths)} palabras
- P√°rrafo m√°s largo: {max(paragraph_lengths)} palabras

‚ö° MOMENTOS DE ACCI√ìN:
- P√°rrafos identificados: {action_paragraphs if action_paragraphs else 'Ninguno detectado'}
- Porcentaje: {len(action_paragraphs) / len(paragraphs) * 100:.1f}%

ü§î MOMENTOS REFLEXIVOS:
- P√°rrafos identificados: {reflective_paragraphs if reflective_paragraphs else 'Ninguno detectado'}
- Porcentaje: {len(reflective_paragraphs) / len(paragraphs) * 100:.1f}%

üéØ EVALUACI√ìN DEL RITMO:
- {rhythm_assessment}
- Balance acci√≥n/reflexi√≥n: {'Equilibrado' if abs(len(action_paragraphs) - len(reflective_paragraphs)) <= 2 else 'Desbalanceado hacia ' + ('acci√≥n' if len(action_paragraphs) > len(reflective_paragraphs) else 'reflexi√≥n')}

üí° RECOMENDACIONES:
- {'A√±adir m√°s momentos de acci√≥n para dinamismo' if len(action_paragraphs) < len(paragraphs) * 0.2 else ''}
- {'Incluir m√°s momentos reflexivos para profundidad' if len(reflective_paragraphs) < len(paragraphs) * 0.2 else ''}
- {'‚úì Buen equilibrio narrativo' if abs(len(action_paragraphs) - len(reflective_paragraphs)) <= 2 else ''}
"""
            return analysis
            
        except Exception as e:
            return f"Error analizando ritmo: {str(e)}"

class PlotAnalyzerInput(BaseModel):
    text: str = Field(..., description="Texto narrativo para analizar la trama")

class PlotAnalyzer(BaseTool):
    name: str = "Analizador de Trama"
    description: str = """
    Analiza la estructura narrativa y elementos de la trama:
    - Identifica puntos de la trama (exposici√≥n, conflicto, cl√≠max, resoluci√≥n)
    - Detecta subtramas
    - Eval√∫a la progresi√≥n narrativa
    """
    args_schema: type[BaseModel] = PlotAnalyzerInput
    
    def _run(self, text: str) -> str:
        """Analiza los elementos de la trama"""
        try:
            # Dividir el texto en secciones
            paragraphs = [p.strip() for p in text.split('\n\n') if p.strip()]
            total_length = len(text.split())
            
            # Detectar elementos de exposici√≥n (t√≠picamente al inicio)
            exposition_markers = ['hab√≠a una vez', 'en un reino', 'hace mucho tiempo', 'era una vez']
            has_exposition = any(marker in text.lower() for marker in exposition_markers)
            
            # Detectar conflicto/tensi√≥n
            conflict_markers = ['pero', 'sin embargo', 'repentinamente', 'de pronto', 'amenaza', 'peligro', 'problema']
            conflict_count = sum(1 for marker in conflict_markers if marker in text.lower())
            
            # Detectar cl√≠max (palabras intensas, t√≠picamente en la parte media-final)
            climax_markers = ['batalla', 'lucha', 'enfrentamiento', 'decisi√≥n', 'momento crucial', 'todo depend√≠a']
            climax_indicators = sum(1 for marker in climax_markers if marker in text.lower())
            
            # Detectar resoluci√≥n
            resolution_markers = ['finalmente', 'al final', 'por √∫ltimo', 'as√≠ fue como', 'desde entonces']
            has_resolution = any(marker in text.lower() for marker in resolution_markers)
            
            # Analizar progresi√≥n temporal
            time_progression = len(re.findall(r'\b(luego|despu√©s|m√°s tarde|entonces|posteriormente)\b', text.lower()))
            
            # Detectar posibles subtramas (cambios de enfoque o personajes)
            character_names = list(set(re.findall(r'\b[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+\b', text)))
            subplot_potential = len(character_names) > 3
            
            # Evaluar estructura general
            structure_score = 0
            structure_feedback = []
            
            if has_exposition:
                structure_score += 1
                structure_feedback.append("‚úì Exposici√≥n presente")
            else:
                structure_feedback.append("‚ö† Exposici√≥n no clara")
            
            if conflict_count > 0:
                structure_score += 1
                structure_feedback.append("‚úì Elementos de conflicto detectados")
            else:
                structure_feedback.append("‚ö† Falta desarrollo del conflicto")
            
            if climax_indicators > 0:
                structure_score += 1
                structure_feedback.append("‚úì Momentos de intensidad presentes")
            else:
                structure_feedback.append("‚ö† Cl√≠max no evidente")
                
            if has_resolution:
                structure_score += 1
                structure_feedback.append("‚úì Resoluci√≥n identificada")
            else:
                structure_feedback.append("‚ö† Resoluci√≥n incompleta")
            
            analysis = f"""AN√ÅLISIS DE TRAMA:
            
üìñ ESTRUCTURA NARRATIVA:
- Puntuaci√≥n estructural: {structure_score}/4
{chr(10).join([f"- {feedback}" for feedback in structure_feedback])}

üî• ELEMENTOS DE TENSI√ìN:
- Marcadores de conflicto: {conflict_count}
- Indicadores de cl√≠max: {climax_indicators}
- Progresi√≥n temporal: {time_progression} transiciones

üë• COMPLEJIDAD NARRATIVA:
- Personajes principales: {len(character_names)}
- Potencial de subtramas: {'Alto' if subplot_potential else 'Bajo'}

‚è≥ FLUJO TEMPORAL:
- Transiciones temporales: {time_progression}
- Progresi√≥n: {'Fluida' if time_progression > 3 else 'Est√°tica'}

üé≠ EVALUACI√ìN GENERAL:
- Estructura: {'S√≥lida' if structure_score >= 3 else 'En desarrollo' if structure_score >= 2 else 'Necesita trabajo'}
- Complejidad: {'Alta' if len(character_names) > 5 else 'Media' if len(character_names) > 2 else 'Simple'}
- Tensi√≥n narrativa: {'Adecuada' if conflict_count > 2 else 'Insuficiente'}

üí° SUGERENCIAS:
- {'Desarrollar m√°s el conflicto central' if conflict_count < 2 else ''}
- {'Clarificar el momento clim√°tico' if climax_indicators == 0 else ''}
- {'Fortalecer la resoluci√≥n' if not has_resolution else ''}
- {'Considerar subtramas para enriquecer la narrativa' if not subplot_potential else ''}
"""
            return analysis
            
        except Exception as e:
            return f"Error analizando trama: {str(e)}"